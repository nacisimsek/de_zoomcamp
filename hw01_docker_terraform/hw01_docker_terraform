####################################
# A1
####################################
colima start --cpu 4 --memory 8 --arch aarch64 --with-kubernetes                                                                                                                            ✔  base   02:16:51 PM 
INFO[0000] starting colima
INFO[0000] runtime: docker+k3s
INFO[0000] starting ...                                  context=vm
INFO[0011] provisioning ...                              context=docker
INFO[0011] starting ...                                  context=docker
INFO[0012] provisioning ...                              context=kubernetes
INFO[0013] starting ...                                  context=kubernetes
INFO[0017] done

docker run --help                                                                                                                                                                           ✔  base   02:17:51 PM 

Usage:  docker run [OPTIONS] IMAGE [COMMAND] [ARG...]

Create and run a new container from an image

Aliases:
  docker container run, docker run

Options:
      --add-host list                  Add a custom host-to-IP mapping (host:ip)
      --annotation map                 Add an annotation to the container (passed through to the OCI runtime) (default map[])
  -a, --attach list                    Attach to STDIN, STDOUT or STDERR
      --blkio-weight uint16            Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)
      --blkio-weight-device list       Block IO weight (relative device weight) (default [])
      --cap-add list                   Add Linux capabilities
      --cap-drop list                  Drop Linux capabilities
      --cgroup-parent string           Optional parent cgroup for the container
      --cgroupns string                Cgroup namespace to use (host|private)
                                       'host':    Run the container in the Docker host's cgroup namespace
                                       'private': Run the container in its own private cgroup namespace
                                       '':        Use the cgroup namespace as configured by the
                                                  default-cgroupns-mode option on the daemon (default)
      --cidfile string                 Write the container ID to the file
      --cpu-period int                 Limit CPU CFS (Completely Fair Scheduler) period
      --cpu-quota int                  Limit CPU CFS (Completely Fair Scheduler) quota
      --cpu-rt-period int              Limit CPU real-time period in microseconds
      --cpu-rt-runtime int             Limit CPU real-time runtime in microseconds
  -c, --cpu-shares int                 CPU shares (relative weight)
      --cpus decimal                   Number of CPUs
      --cpuset-cpus string             CPUs in which to allow execution (0-3, 0,1)
      --cpuset-mems string             MEMs in which to allow execution (0-3, 0,1)
  -d, --detach                         Run container in background and print container ID
      --detach-keys string             Override the key sequence for detaching a container
      --device list                    Add a host device to the container
      --device-cgroup-rule list        Add a rule to the cgroup allowed devices list
      --device-read-bps list           Limit read rate (bytes per second) from a device (default [])
      --device-read-iops list          Limit read rate (IO per second) from a device (default [])
      --device-write-bps list          Limit write rate (bytes per second) to a device (default [])
      --device-write-iops list         Limit write rate (IO per second) to a device (default [])
      --disable-content-trust          Skip image verification (default true)
      --dns list                       Set custom DNS servers
      --dns-option list                Set DNS options
      --dns-search list                Set custom DNS search domains
      --domainname string              Container NIS domain name
      --entrypoint string              Overwrite the default ENTRYPOINT of the image
  -e, --env list                       Set environment variables
      --env-file list                  Read in a file of environment variables
      --expose list                    Expose a port or a range of ports
      --gpus gpu-request               GPU devices to add to the container ('all' to pass all GPUs)
      --group-add list                 Add additional groups to join
      --health-cmd string              Command to run to check health
      --health-interval duration       Time between running the check (ms|s|m|h) (default 0s)
      --health-retries int             Consecutive failures needed to report unhealthy
      --health-start-period duration   Start period for the container to initialize before starting health-retries countdown (ms|s|m|h) (default 0s)
      --health-timeout duration        Maximum time to allow one check to run (ms|s|m|h) (default 0s)
      --help                           Print usage
  -h, --hostname string                Container host name
      --init                           Run an init inside the container that forwards signals and reaps processes
  -i, --interactive                    Keep STDIN open even if not attached
      --ip string                      IPv4 address (e.g., 172.30.100.104)
      --ip6 string                     IPv6 address (e.g., 2001:db8::33)
      --ipc string                     IPC mode to use
      --isolation string               Container isolation technology
      --kernel-memory bytes            Kernel memory limit
  -l, --label list                     Set meta data on a container
      --label-file list                Read in a line delimited file of labels
      --link list                      Add link to another container
      --link-local-ip list             Container IPv4/IPv6 link-local addresses
      --log-driver string              Logging driver for the container
      --log-opt list                   Log driver options
      --mac-address string             Container MAC address (e.g., 92:d0:c6:0a:29:33)
  -m, --memory bytes                   Memory limit
      --memory-reservation bytes       Memory soft limit
      --memory-swap bytes              Swap limit equal to memory plus swap: '-1' to enable unlimited swap
      --memory-swappiness int          Tune container memory swappiness (0 to 100) (default -1)
      --mount mount                    Attach a filesystem mount to the container
      --name string                    Assign a name to the container
      --network network                Connect a container to a network
      --network-alias list             Add network-scoped alias for the container
      --no-healthcheck                 Disable any container-specified HEALTHCHECK
      --oom-kill-disable               Disable OOM Killer
      --oom-score-adj int              Tune host's OOM preferences (-1000 to 1000)
      --pid string                     PID namespace to use
      --pids-limit int                 Tune container pids limit (set -1 for unlimited)
      --platform string                Set platform if server is multi-platform capable
      --privileged                     Give extended privileges to this container
  -p, --publish list                   Publish a container's port(s) to the host
  -P, --publish-all                    Publish all exposed ports to random ports
      --pull string                    Pull image before running ("always", "missing", "never") (default "missing")
  -q, --quiet                          Suppress the pull output
      --read-only                      Mount the container's root filesystem as read only
      --restart string                 Restart policy to apply when a container exits (default "no")
      --rm                             Automatically remove the container when it exits




--rm                             Automatically remove the container when it exits

####################################
# A2
####################################
docker run -it --entrypoint bash python:3.9                                                                                                                                                 ✔  base   02:19:16 PM 
Unable to find image 'python:3.9' locally
3.9: Pulling from library/python
5665c1f9a9e1: Pull complete
f419b1a62fc8: Pull complete
76b4f1810f99: Pull complete
1c176cbf6497: Pull complete
ba0d9396537e: Pull complete
cf458769c92c: Pull complete
a76a1914532c: Pull complete
03729fef6de7: Pull complete
Digest: sha256:3d9dbe78e1f45ed2eb525b462cdb02247cc0956713325aeeffa37cb5f2c8c42e
Status: Downloaded newer image for python:3.9
root@8445117d7909:/#
root@8445117d7909:/#
root@8445117d7909:/# pip list
Package    Version
---------- -------
pip        23.0.1
setuptools 58.1.0
wheel      0.42.0

####################################
# A3
####################################
Prerequisities:
Install Postgres Using Helm
Install Jupyter Lab and its environment

# Push the CSV files to Postgres
####################################
import sys
print(sys.executable)
import pandas as pd
from sqlalchemy import create_engine

# Database connection details
db_username = 'postgres'
db_password = 'oNsOZrwiDX'
db_host = 'localhost'
db_port = '5432'
db_name = 'postgres'
schema_name = 'public'  # Custom schema name
table_name = 'green_tripdata'

# Connection string for SQLAlchemy
connection_string = f"postgresql://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}"
engine = create_engine(connection_string)

# Reading CSV file
csv_file_path = 'zoomcamp_hw01/green_tripdata_2019-09.csv'
df = pd.read_csv(csv_file_path)

print(df.dtypes)

df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])
df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'])

print(df.dtypes)

df.to_sql(table_name, engine, schema=schema_name, if_exists='replace', index=False)

csv_file_path2 = 'zoomcamp_hw01/taxi+_zone_lookup.csv'
df2 = pd.read_csv(csv_file_path2)

print(df2.dtypes)

table2_name = 'taxi_zone'
df2.to_sql(table2_name, engine, schema=schema_name, if_exists='replace', index=False)




SELECT COUNT(*) 
FROM public.green_tripdata
WHERE 
    lpep_pickup_datetime >= '2019-09-18 00:00:00'
    AND lpep_pickup_datetime < '2019-09-19 00:00:00'
    AND lpep_dropoff_datetime >= '2019-09-18 00:00:00'
    AND lpep_dropoff_datetime < '2019-09-19 00:00:00'

count|
-----+
15612|

####################################
# A4
####################################
SELECT 
    DATE(lpep_pickup_datetime) AS pickup_date,
    SUM(trip_distance) AS total_distance
FROM 
    public.green_tripdata
GROUP BY 
    DATE(lpep_pickup_datetime)
ORDER BY 
    total_distance DESC
LIMIT 1

pickup_date|total_distance  |
-----------+----------------+
 2019-09-26|58759.9400000002|


 ####################################
 # A5
 ####################################

SELECT 
    l."Borough" ,
    SUM(t.total_amount) AS total_amount_sum
FROM 
    public.green_tripdata t
JOIN 
    public.taxi_zone l ON t."PULocationID"  = l."LocationID" 
WHERE 
    DATE(t.lpep_pickup_datetime) = '2019-09-18'
    AND l."Borough"  <> 'Unknown'
GROUP BY 
    l."Borough" 
HAVING 
    SUM(t.total_amount) > 50000
ORDER BY 
    total_amount_sum DESC
LIMIT 3

Borough  |total_amount_sum |
---------+-----------------+
Brooklyn |96333.24000000149|
Manhattan|92271.30000000617|
Queens   |78671.71000000356|


 ####################################
 # A6
 ####################################

 SELECT 
    dropoff."Zone"  AS dropoff_zone,
    MAX(t.tip_amount) AS largest_tip
FROM 
    public.green_tripdata t
inner JOIN 
    public.taxi_zone pickup ON t."PULocationID"  = pickup."LocationID" 
inner JOIN 
    public.taxi_zone dropoff ON t."DOLocationID"  = dropoff."LocationID" 
WHERE 
    pickup."Zone" = 'Astoria'
    AND DATE(t.lpep_pickup_datetime) BETWEEN '2019-09-01' AND '2019-09-30'
GROUP BY 
    dropoff."Zone" 
ORDER BY 
    largest_tip DESC
LIMIT 1

dropoff_zone|largest_tip|
------------+-----------+
JFK Airport |      62.31|



 ####################################
 # A7
 ####################################


terraform apply                              ✔  6s   base   03:18:46 PM 

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_bigquery_dataset.demo_dataset will be created
  + resource "google_bigquery_dataset" "demo_dataset" {
      + creation_time              = (known after apply)
      + dataset_id                 = "demo_dataset"
      + default_collation          = (known after apply)
      + delete_contents_on_destroy = false
      + effective_labels           = (known after apply)
      + etag                       = (known after apply)
      + id                         = (known after apply)
      + is_case_insensitive        = (known after apply)
      + last_modified_time         = (known after apply)
      + location                   = "EU"
      + max_time_travel_hours      = (known after apply)
      + project                    = "symmetric-span-412518"
      + self_link                  = (known after apply)
      + storage_billing_model      = (known after apply)
      + terraform_labels           = (known after apply)
    }

  # google_storage_bucket.demo-bucket will be created
  + resource "google_storage_bucket" "demo-bucket" {
      + effective_labels            = (known after apply)
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "EU"
      + name                        = "terraform-demo-bucket-naci-001"
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + terraform_labels            = (known after apply)
      + uniform_bucket_level_access = (known after apply)
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type = "AbortIncompleteMultipartUpload"
            }
          + condition {
              + age                   = 1
              + matches_prefix        = []
              + matches_storage_class = []
              + matches_suffix        = []
              + with_state            = (known after apply)
            }
        }
    }

Plan: 2 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

google_bigquery_dataset.demo_dataset: Creating...
google_storage_bucket.demo-bucket: Creating...
google_bigquery_dataset.demo_dataset: Creation complete after 4s [id=projects/symmetric-span-412518/datasets/demo_dataset]
google_storage_bucket.demo-bucket: Creation complete after 2s [id=terraform-demo-bucket-naci-001]
Apply complete! Resources: 2 added, 0 changed, 0 destroyed.